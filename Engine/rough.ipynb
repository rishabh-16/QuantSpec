{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def draft_update(k_cache, v_cache, k, v, cache_seqlens, qcache_seqlens):\n",
    "    # Create indices for scatter operation\n",
    "    bsz, num_heads, update_len, head_dim = k.shape\n",
    "    seq_len = k_cache.shape[2]\n",
    "    \n",
    "    # Create index tensor for scatter\n",
    "    indices = torch.arange(update_len, device=k.device)\n",
    "    indices = indices.view(1, 1, -1, 1)  # [1, 1, update_len, 1]\n",
    "    indices = indices + qcache_seqlens.view(-1, 1, 1, 1)  # [bsz, 1, update_len, 1]\n",
    "    indices = indices.expand(bsz, num_heads, update_len, head_dim)\n",
    "    print(indices)\n",
    "    \n",
    "    # Perform scatter operations\n",
    "    k_cache.scatter_(dim=2, index=indices, src=k)\n",
    "    v_cache.scatter_(dim=2, index=indices, src=v)\n",
    "    \n",
    "    return k_cache, v_cache\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draft_update(k_cache, v_cache, k, v, cache_seqlens, qcache_seqlens):\n",
    "    bsz = k_cache.shape[0]\n",
    "    assert bsz == 1, \"Batch size > 1 not supported yet\"\n",
    "    \n",
    "    # Calculate start index for the current batch\n",
    "    start_idx = qcache_seqlens[0]  # Using only first batch element since bsz=1\n",
    "    seq_len = k_cache.shape[2]\n",
    "    \n",
    "    # Create a mask for valid positions\n",
    "    # This avoids data-dependent indexing by operating on the full tensor\n",
    "    position_indices = torch.arange(self.k_cache.shape[2], device=k_cache.device)\n",
    "    valid_positions = (position_indices >= start_idx) & (position_indices < start_idx + seq_len)\n",
    "    \n",
    "    # Expand mask to match cache dimensions\n",
    "    mask = valid_positions.view(1, 1, -1, 1).expand_as(self.k_cache[:, :, :, :])\n",
    "    \n",
    "    # Create expanded k_cache and v_cache\n",
    "    expanded_k = k_cache.unsqueeze(2).expand(-1, -1, self.k_cache.shape[2], -1)\n",
    "    expanded_v = v_cache.unsqueeze(2).expand(-1, -1, self.v_cache.shape[2], -1)\n",
    "    \n",
    "    # Use masked operations instead of direct indexing\n",
    "    self.k_cache = torch.where(mask, expanded_k, self.k_cache)\n",
    "    self.v_cache = torch.where(mask, expanded_v, self.v_cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]],\n",
      "\n",
      "         [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]],\n",
      "\n",
      "         [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]],\n",
      "\n",
      "         [[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]],\n",
      "\n",
      "\n",
      "        [[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "         [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "         [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "\n",
      "         [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]]])\n",
      "All tests passed!\n"
     ]
    }
   ],
   "source": [
    "def test_draft_update():\n",
    "    # Create test inputs\n",
    "    batch_size = 2\n",
    "    num_heads = 4\n",
    "    seq_len = 8\n",
    "    head_dim = 16\n",
    "    \n",
    "    # Create sample caches\n",
    "    k_cache = torch.zeros(batch_size, num_heads, seq_len, head_dim)\n",
    "    v_cache = torch.zeros(batch_size, num_heads, seq_len, head_dim)\n",
    "    k = torch.randn(batch_size, num_heads, 1, head_dim)\n",
    "    v = torch.randn(batch_size, num_heads, 1, head_dim)\n",
    "    \n",
    "    # Create sample sequence lengths\n",
    "    cache_seqlens = torch.tensor([6, 4])  # Different lengths for each batch\n",
    "    qcache_seqlens = torch.tensor([2, 1])  # Different starting points\n",
    "    \n",
    "    # Keep copies of original caches\n",
    "    k_cache_orig = k_cache.clone()\n",
    "    v_cache_orig = v_cache.clone()\n",
    "    \n",
    "    # Run the function\n",
    "    k_out, v_out = draft_update(k_cache, v_cache,k,v, cache_seqlens, qcache_seqlens)\n",
    "    \n",
    "    # Verify shapes haven't changed\n",
    "    assert k_out.shape == k_cache_orig.shape\n",
    "    assert v_out.shape == v_cache_orig.shape\n",
    "    \n",
    "    # Verify the updates happened at correct positions\n",
    "    for b in range(batch_size):\n",
    "        start_idx = qcache_seqlens[b]\n",
    "        end_idx = qcache_seqlens[b] + k.shape[2]\n",
    "        \n",
    "        # Check that values were copied correctly\n",
    "        assert torch.allclose(k_out[b, :, start_idx:end_idx], k[b])\n",
    "        assert torch.allclose(v_out[b, :, start_idx:end_idx], v[b])\n",
    "        \n",
    "        # Check that values outside update range remain unchanged\n",
    "        if start_idx > 0:\n",
    "            assert torch.allclose(k_out[b, :, :start_idx], k_cache_orig[b, :, :start_idx])\n",
    "            assert torch.allclose(v_out[b, :, :start_idx], v_cache_orig[b, :, :start_idx])\n",
    "        if end_idx < seq_len:\n",
    "            assert torch.allclose(k_out[b, :, end_idx:], k_cache_orig[b, :, end_idx:])\n",
    "            assert torch.allclose(v_out[b, :, end_idx:], v_cache_orig[b, :, end_idx:])\n",
    "    \n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "# Run the test\n",
    "test_draft_update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3847217/3799017049.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask = torch.tensor(mask)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True, False, False],\n",
       "        [False, False,  True,  True, False]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bsz = 2\n",
    "seq_len = 5\n",
    "\n",
    "mask = torch.arange(seq_len).unsqueeze(0) >= index_list.unsqueeze(1)\n",
    "mask &= torch.arange(seq_len).unsqueeze(0) < (index_list + a.shape[1]).unsqueeze(1)\n",
    "mask = torch.tensor(mask)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5959],\n",
       "        [ 0.0472],\n",
       "        [-0.8919],\n",
       "        [-0.2357]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "A[mask] = a.view(-1,a.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2664, -1.1244,  0.1311,  1.5670, -0.5227, -0.0628, -0.3672,\n",
       "           0.7776, -0.6443,  0.5735],\n",
       "         [ 1.2952, -1.7487,  0.5188, -0.9836,  0.3290,  0.1861,  1.1023,\n",
       "          -1.0282,  0.1419,  0.3721],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 2.0867, -1.0878, -1.5198, -0.6441,  1.2848,  0.5716, -0.1964,\n",
       "          -1.4325,  0.4747,  0.7528],\n",
       "         [ 0.6980, -0.2796,  0.1953,  0.0589,  1.1897,  0.2222,  0.0208,\n",
       "          -1.0235,  0.4140, -1.9478],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 10])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 0.2664, -1.1244,  0.1311,  1.5670, -0.5227, -0.0628, -0.3672,\n",
       "           0.7776, -0.6443,  0.5735],\n",
       "         [ 1.2952, -1.7487,  0.5188, -0.9836,  0.3290,  0.1861,  1.1023,\n",
       "          -1.0282,  0.1419,  0.3721],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000],\n",
       "         [ 2.0867, -1.0878, -1.5198, -0.6441,  1.2848,  0.5716, -0.1964,\n",
       "          -1.4325,  0.4747,  0.7528],\n",
       "         [ 0.6980, -0.2796,  0.1953,  0.0589,  1.1897,  0.2222,  0.0208,\n",
       "          -1.0235,  0.4140, -1.9478],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.zeros(2, 5, 10)\n",
    "# a = torch.randn(2, 2, 10)\n",
    "\n",
    "index_list = torch.tensor([1, 2]) # 2, 2, 5\n",
    "A[0, 1:1+a.shape[1], :] = a[0] \n",
    "A[1, 2:2+a.shape[1], :] = a[1]\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 5])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=torch.tensor([1, 2]).view(1, 2, 1).repeat(2,1,5)\n",
    "index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.2241, -1.1241, -1.8280, -0.4621,  0.3573],\n",
      "         [-0.3164,  0.9304,  0.2137, -0.8889, -1.4511],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.4408,  0.6711,  3.1076, -0.6692,  0.4591],\n",
      "         [-0.6139,  0.2703,  0.3493, -2.3580, -0.8639],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "A.scatter_(dim=1, index=index, src=a)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.2241, -1.1241, -1.8280, -0.4621,  0.3573],\n",
       "        [-0.3164,  0.9304,  0.2137, -0.8889, -1.4511],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(5, 3)\n",
    "t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float)\n",
    "index = torch.tensor([0, 4, 2])\n",
    "# x.index_copy_(0, index, t)\n",
    "# tensor([[ 1.,  2.,  3.],\n",
    "#         [ 0.,  0.,  0.],\n",
    "#         [ 7.,  8.,  9.],\n",
    "#         [ 0.,  0.,  0.],\n",
    "#         [ 4.,  5.,  6.]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]),\n",
       " torch.Size([3, 3]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.],\n",
       "         [0., 0., 0.]]),\n",
       " torch.Size([5, 3]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magicdec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
